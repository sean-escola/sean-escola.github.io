<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Proposal for a NeuroAI FRO | Sean Escola </title> <meta name="author" content="Sean Escola"> <meta name="description" content="Following the path forged by the evolution of the brain to build better intelligence"> <meta name="keywords" content="neuroscience, AI, learning, sensorimotor-control, RNNs, deep-reinforcement-learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sean-escola.github.io/blog/2024/neuroai/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Proposal for a NeuroAI FRO",
            "description": "Following the path forged by the evolution of the brain to build better intelligence",
            "published": "May 16, 2024",
            "authors": [
              
              {
                "author": "Sean Escola",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Columbia University",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sean</span> Escola </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Proposal for a NeuroAI FRO</h1> <p>Following the path forged by the evolution of the brain to build better intelligence</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#virtual-neuroscience">Virtual neuroscience</a> </div> <div> <a href="#goal">Goal</a> </div> <div> <a href="#deliverable">Deliverable</a> </div> <div> <a href="#why-an-fro">Why an FRO</a> </div> </nav> </d-contents> <h2 id="virtual-neuroscience">Virtual neuroscience</h2> <p>The evolution of humans and other animals provides an existence proof for the tantalizing possibility of a foundation model for general intelligence. Notably, the specific driver of the 500 million years of evolution that gave rise to the mammalian brain was the need to solve the problem of sensorimotor control – i.e., the agile control of biomechanical bodies with limited degrees of freedom in the context of noise, sensory feedback delays, and unstructured real environments subject to physics. In contrast, all abstract cognitive phenomena that we think of as the domain of advanced intelligence (language, art, science, games, etc.) arose in merely the last 200 thousand years, an insufficient timespan for substantial evolutionary shaping of neural circuits. In other words, the foundation model for general intelligence is the circuit structure and learning mechanisms underlying sensorimotor control. This provides a roadmap for accelerating research: build artificial systems that robustly solve sensorimotor control in a manner akin to biological systems and then use them both to understand the neuroscience of natural intelligence and as a starting point for developing advanced AI. This is the purpose of Zoo AI, the FRO we propose.</p> <h2 id="goal">Goal</h2> <p>The standard academic approach of reductionism has failed to reveal the secrets of ecologically relevant behaviors such as, e.g., social interaction, complex sequence learning and execution, and multi-step memory-guided decision-making on both short and life-long timescales. A hypothesis for this is that the flexibility, robustness, and generalizability that these functions require arise through the constraints of brains needing to control bodies to behave. If so, neural computations must be studied, not via reductionism, but rather in the complex context of the biomechanics of the body and the physics of the world. We can now achieve this in simulation because of the convergence of several technologies:</p> <ol> <li>Massively scaled datasets for animals of interest comprising near-complete full-body 3D behavioral ethograms paired with neural physiology and/or casual neural manipulations.</li> <li>High-resolution anatomy (e.g., via micro-CT) for detailed musculoskeletal model design.</li> <li>Fast, flexible physics simulators (e.g., GPU/TPU enabled Mujoco 3.0).</li> <li>Deep RL and imitation learning for training <em>in silico</em> animal models to match the behavior of their in vivo counterparts.</li> </ol> <p>This final point is critical because the evolutionary history described above aligns with Moravec’s paradox: solving sensorimotor control is hard (requiring 500 million years of primate evolution) while tackling cognitive phenomena is relatively easy (requiring just a few hundred thousand years). Imitation learning allows us to skip the first step and build models with the sensorimotor control capabilities of real animals by copying nature’s solution.</p> <p>These models can then serve many important functions including as:</p> <ol> <li>Neuroscience research platforms for scaled hypothesis generation and fully transparent virtual experimentation.</li> <li>Inductive biases for the development of use-specific models (i.e., in the vein of how foundation models for language and vision are used today as starting points for models with domain specificity).</li> <li>Initial solutions for sim-to-real transfer for fully agile robotics platforms.</li> </ol> <p>Developing an <em>in silico</em> zoo – comprising worms, flies, fish, birds, rodents, non-human primates, and humans – would allow the same technical infrastructure to benefit many scientific communities and, critically, will provide a path toward distilling the common principles of sensorimotor control which all animals share and that thus constitute the core of natural intelligence.</p> <h2 id="deliverable">Deliverable</h2> <p>The FRO’s explicit deliverable will be a completely novel open-source neuroscience research platform comprising virtual animals of multiple species and tools for experimenting with them. Pre-trained plug-and-play modules will enable users to tune up and down the realism along the brain–body–behavior axis as needed for scientific questions of interest. E.g., options will include (i) constraining part or all of a virtual fly’s brain by the connectome, and (ii) having neural outputs drive joint torques versus muscle activations. APIs will be provided for integrating new (i) behavioral data (for model training), (ii) neural data (for comparison between virtual and real animals), and (iii) biomechanical and neuroanatomical/connectomic data (for adding species). These models will be living repositories for all that we know about the neuroscience of these animals. Such a platform will become the principal driver of discovery in neuroscience and will reposition laboratory experiments to the supporting roles of confirming virtual experiments and guiding model refinement. This would echo the shift in physics to a simulation-first approach.</p> <h2 id="why-an-fro">Why an FRO</h2> <p>Building virtual neuroscience cannot be achieved within academia because existing funding structures do not have the timescale or risk tolerance for a project of this ambition and because of the multidisciplinary and deep engineering aspects of the project. Whereas academic labs hire mostly within a single discipline, the complexity of our technology stack means that we need to hire scientists and engineers from many backgrounds, including experts in physics simulation, biomechanical modeling, deep RL, generative AI, computational ethology, behavioral data analysis, neural data analysis, computer vision, neural circuit theory, and machine learning infrastructure. This interdisciplinary approach is at odds with the incentive structure of career advancement in academia. Moreover, academic labs have a poor record of attracting the kind of high-value software engineers we require: those who can build and maintain scalable, robust, powerful tools that are also easy to adopt by end users across academic and industry professionals with varying degrees of technical expertise. Of note, while we may or may not collect experimental data within the FRO itself, we will certainly maintain extensive collaborations with academics for 3D videography data paired with neural recordings and/or perturbations, anatomical and biomechanical measurements, and beta-testing and feedback as we build our models. These collaborations will unlock a virtuous cycle, with models directing experiments to questions of high value and the answers to these questions informing model refinement.</p> <p>A venture-backed robotics company could potentially achieve the more limited goal of developing robust motor control. But the idea of instantiating virtual animals in simulation for the purpose of understanding intelligence generally (as well as motor control) requires a funding commitment for the achievement of a scientific, not a commercial, goal. OpenAI is the most obvious recent point of comparison here, and – though OpenAI now has a valuable product – its initial funding was non-standard and similar in concept to FRO funding. Thus, a company would not be the correct structure for achieving our goals. Importantly though, the FRO funding model imports the ethos from the startup world – which has shown repeated success over recent decades – that the successful development of novel technology that can overturn a status quo demands a rapid decision-making culture that is anathema to the academy.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-05-16-neuroai.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"sean-escola/sean-escola.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Sean Escola. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>